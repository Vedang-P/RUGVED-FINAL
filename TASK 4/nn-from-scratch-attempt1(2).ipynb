{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285},{"sourceId":11976128,"sourceType":"datasetVersion","datasetId":7531458}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:04.549489Z","iopub.execute_input":"2025-05-28T13:44:04.549816Z","iopub.status.idle":"2025-05-28T13:44:04.554329Z","shell.execute_reply.started":"2025-05-28T13:44:04.549773Z","shell.execute_reply":"2025-05-28T13:44:04.553463Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/nn-from-scratch-1/train 2.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:05.500552Z","iopub.execute_input":"2025-05-28T13:44:05.501482Z","iopub.status.idle":"2025-05-28T13:44:07.663044Z","shell.execute_reply.started":"2025-05-28T13:44:05.501451Z","shell.execute_reply":"2025-05-28T13:44:07.662346Z"}},"outputs":[],"execution_count":111},{"cell_type":"markdown","source":"preprocessing the data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:08.072986Z","iopub.execute_input":"2025-05-28T13:44:08.073723Z","iopub.status.idle":"2025-05-28T13:44:08.086427Z","shell.execute_reply.started":"2025-05-28T13:44:08.073686Z","shell.execute_reply":"2025-05-28T13:44:08.085621Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:09.252772Z","iopub.execute_input":"2025-05-28T13:44:09.253047Z","iopub.status.idle":"2025-05-28T13:44:10.901572Z","shell.execute_reply.started":"2025-05-28T13:44:09.253026Z","shell.execute_reply":"2025-05-28T13:44:10.900929Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \nmean       0.0      0.0      0.0  ...      0.219286      0.117095   \nstd        0.0      0.0      0.0  ...      6.312890      4.633819   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:12.097933Z","iopub.execute_input":"2025-05-28T13:44:12.098220Z","iopub.status.idle":"2025-05-28T13:44:12.143163Z","shell.execute_reply.started":"2025-05-28T13:44:12.098199Z","shell.execute_reply":"2025-05-28T13:44:12.142519Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"label       0\npixel0      0\npixel1      0\npixel2      0\npixel3      0\n           ..\npixel779    0\npixel780    0\npixel781    0\npixel782    0\npixel783    0\nLength: 785, dtype: int64"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"df=np.array(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:13.954834Z","iopub.execute_input":"2025-05-28T13:44:13.955466Z","iopub.status.idle":"2025-05-28T13:44:14.051900Z","shell.execute_reply.started":"2025-05-28T13:44:13.955441Z","shell.execute_reply":"2025-05-28T13:44:14.051201Z"}},"outputs":[],"execution_count":115},{"cell_type":"markdown","source":"Shuffling introduces randomness that prevents biased learning, basically prevents overfitting,if you train in batches,it can get biased to each class","metadata":{}},{"cell_type":"code","source":"m,n=df.shape\nnp.random.shuffle(df)\nprint(m,n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:16.018127Z","iopub.execute_input":"2025-05-28T13:44:16.018602Z","iopub.status.idle":"2025-05-28T13:44:16.539815Z","shell.execute_reply.started":"2025-05-28T13:44:16.018579Z","shell.execute_reply":"2025-05-28T13:44:16.538876Z"}},"outputs":[{"name":"stdout","text":"42000 785\n","output_type":"stream"}],"execution_count":116},{"cell_type":"markdown","source":"m= no of total images \nn = no of features (all individual pixel data) + 1 (label)","metadata":{}},{"cell_type":"code","source":"df_val_dataset = df[0:1000].T\nY_val = df_val_dataset[0]\nX_val = df_val_dataset[1:n]\nX_val=X_val/255.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:18.486142Z","iopub.execute_input":"2025-05-28T13:44:18.486674Z","iopub.status.idle":"2025-05-28T13:44:18.494534Z","shell.execute_reply.started":"2025-05-28T13:44:18.486648Z","shell.execute_reply":"2025-05-28T13:44:18.493746Z"}},"outputs":[],"execution_count":117},{"cell_type":"markdown","source":"making a validation dataset before training the model,here we adjust the hyperparameters and check if the model is actually learning and not overfitting,here i'm taking 2000 examples for validation dataset","metadata":{}},{"cell_type":"markdown","source":"taking transpose makes the df_val matrix such that now each column is an example , thus we now have a matrix of 785x2000","metadata":{}},{"cell_type":"code","source":"print(df_val_dataset.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:19.860617Z","iopub.execute_input":"2025-05-28T13:44:19.861480Z","iopub.status.idle":"2025-05-28T13:44:19.865317Z","shell.execute_reply.started":"2025-05-28T13:44:19.861451Z","shell.execute_reply":"2025-05-28T13:44:19.864552Z"}},"outputs":[{"name":"stdout","text":"(785, 1000)\n","output_type":"stream"}],"execution_count":118},{"cell_type":"markdown","source":"now we will train on the remaining data","metadata":{}},{"cell_type":"code","source":"df_train = df[1000:m].T\n\n\ndf_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:21.867657Z","iopub.execute_input":"2025-05-28T13:44:21.867986Z","iopub.status.idle":"2025-05-28T13:44:21.873315Z","shell.execute_reply.started":"2025-05-28T13:44:21.867963Z","shell.execute_reply":"2025-05-28T13:44:21.872566Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"(785, 41000)"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"Y_train=df_train[0]\nX_train=df_train[1:n]\nX_train=X_train/255.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:23.545259Z","iopub.execute_input":"2025-05-28T13:44:23.545764Z","iopub.status.idle":"2025-05-28T13:44:23.822758Z","shell.execute_reply.started":"2025-05-28T13:44:23.545740Z","shell.execute_reply":"2025-05-28T13:44:23.822042Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"print(Y_val)\nprint(\"///////////\")\nprint(X_val)\nprint(\"///////////\")\nprint(Y_train)\nprint(\"///////////\")\nprint(X_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:24.167237Z","iopub.execute_input":"2025-05-28T13:44:24.167834Z","iopub.status.idle":"2025-05-28T13:44:24.174954Z","shell.execute_reply.started":"2025-05-28T13:44:24.167810Z","shell.execute_reply":"2025-05-28T13:44:24.174093Z"}},"outputs":[{"name":"stdout","text":"[6 4 4 5 5 4 1 1 3 1 3 0 1 7 7 8 4 5 4 1 3 8 0 2 8 4 6 5 5 6 5 0 4 0 9 1 2\n 6 9 4 2 0 0 3 9 6 3 3 9 6 9 1 7 7 1 3 8 5 4 3 1 8 3 7 0 2 9 9 4 4 7 3 2 4\n 2 4 6 8 2 7 0 4 7 0 9 5 0 6 5 7 2 7 5 6 7 7 9 1 0 4 6 1 1 3 0 5 8 1 1 3 5\n 0 0 4 0 4 3 9 1 5 1 2 1 8 7 4 5 4 5 5 6 4 9 9 2 1 7 2 8 1 1 6 4 4 9 4 2 5\n 8 0 6 3 2 6 5 0 6 3 3 6 0 4 6 1 4 0 1 7 0 8 5 2 7 7 3 9 2 5 5 0 5 6 2 9 1\n 7 4 1 6 4 5 1 7 1 7 6 4 8 5 8 2 9 6 3 4 0 0 2 3 8 7 8 7 7 8 7 8 4 7 2 8 9\n 9 0 1 4 5 2 0 1 3 4 2 1 0 5 4 3 0 1 1 9 6 1 4 9 9 3 3 9 7 5 0 6 7 9 2 1 6\n 5 1 2 1 3 2 4 4 0 3 4 1 4 5 2 5 1 6 4 6 1 9 4 4 8 0 2 7 3 0 2 4 0 8 7 3 1\n 4 2 1 6 0 8 7 9 6 2 5 3 4 6 7 7 2 9 7 1 2 7 5 5 0 4 4 3 9 7 6 3 4 8 4 4 4\n 2 7 9 2 3 3 2 7 0 5 3 8 5 1 1 2 5 1 0 7 1 6 9 0 9 5 1 3 4 9 0 0 8 7 3 5 8\n 6 8 1 6 7 0 3 4 8 7 3 2 8 0 0 4 1 2 1 6 9 9 9 6 2 0 5 1 1 4 3 7 6 9 3 6 5\n 7 4 5 1 7 7 8 7 1 1 8 3 9 4 2 1 9 3 9 4 9 5 6 1 8 2 0 7 4 4 4 4 6 7 0 3 4\n 7 7 6 6 9 5 9 8 9 8 7 7 1 7 8 1 3 2 2 2 0 7 6 1 7 5 3 0 6 6 2 2 4 2 3 6 9\n 3 5 4 7 4 7 8 4 3 6 5 2 8 9 5 4 4 7 0 7 5 1 6 7 0 8 7 3 3 5 5 7 5 6 4 9 1\n 7 0 7 6 7 6 5 9 2 8 4 1 1 1 5 3 6 6 9 2 8 1 6 6 9 4 6 0 8 4 5 1 4 4 6 3 8\n 5 1 3 1 2 1 2 3 9 8 7 9 0 7 2 5 4 4 1 9 9 5 0 1 0 7 4 4 4 0 2 2 6 0 9 6 3\n 8 3 7 8 2 0 5 0 1 2 3 6 3 0 2 3 9 5 7 1 6 8 7 4 4 5 3 4 5 7 9 0 8 3 0 3 6\n 9 0 4 9 5 0 1 1 5 9 4 3 0 2 1 2 2 0 9 3 4 1 9 0 2 9 1 0 1 5 2 0 7 7 7 8 5\n 5 0 5 1 5 9 1 9 7 0 1 0 9 6 1 5 7 2 9 5 7 6 3 8 7 4 1 4 2 1 9 1 1 7 0 5 0\n 4 2 2 6 9 6 9 7 9 2 4 9 9 0 9 6 9 1 9 3 7 6 5 0 5 3 4 5 3 2 0 9 5 2 4 8 5\n 8 2 3 4 4 8 6 8 9 9 7 4 2 0 5 3 2 8 7 3 2 8 4 7 8 2 2 2 2 8 7 4 8 0 9 3 7\n 0 9 9 9 9 1 1 0 8 1 3 6 6 1 1 8 6 7 9 5 7 7 9 6 5 9 5 5 9 1 1 9 9 0 7 8 6\n 7 9 4 2 8 0 5 8 4 7 1 1 4 5 4 9 4 8 9 4 6 0 5 5 9 4 7 1 1 1 3 7 7 7 8 0 4\n 0 1 2 8 8 4 9 8 1 4 0 6 6 9 2 7 4 4 4 3 3 1 6 0 8 6 6 5 5 7 4 4 2 2 5 4 8\n 9 6 9 9 4 8 0 0 0 7 7 8 6 5 8 0 9 0 5 6 1 8 3 3 0 4 6 4 2 7 8 3 8 7 9 7 2\n 0 2 6 2 3 9 5 5 4 1 5 1 6 0 1 1 8 2 6 0 3 9 1 3 5 8 6 1 1 5 6 1 8 0 0 8 4\n 8 8 0 1 9 2 0 4 8 3 1 1 8 7 0 5 6 6 1 5 0 4 2 8 7 7 1 3 9 5 3 8 5 6 7 5 9\n 4]\n///////////\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n///////////\n[4 3 6 ... 1 4 5]\n///////////\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"Y_val/Y_train containss all the label info\nX_val/X_train contains all the pixel data","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(X_train).head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:28.659505Z","iopub.execute_input":"2025-05-28T13:44:28.659846Z","iopub.status.idle":"2025-05-28T13:44:28.683970Z","shell.execute_reply.started":"2025-05-28T13:44:28.659822Z","shell.execute_reply":"2025-05-28T13:44:28.683196Z"}},"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"   0      1      2      3      4      5      6      7      8      9      ...  \\\n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n\n   40990  40991  40992  40993  40994  40995  40996  40997  40998  40999  \n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n\n[5 rows x 41000 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>40990</th>\n      <th>40991</th>\n      <th>40992</th>\n      <th>40993</th>\n      <th>40994</th>\n      <th>40995</th>\n      <th>40996</th>\n      <th>40997</th>\n      <th>40998</th>\n      <th>40999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41000 columns</p>\n</div>"},"metadata":{}}],"execution_count":122},{"cell_type":"markdown","source":"the data is now loaded,now we define the initilizing parameters","metadata":{}},{"cell_type":"code","source":" def initialize_parameters():\n     W1=np.random.rand(10,784) - 0.5\n     b1=np.random.rand(10,1) - 0.5\n     W2=np.random.rand(10,10) - 0.5\n     b2=np.random.rand(10,1) - 0.5\n     return W1,b1,W2,b2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:30.722211Z","iopub.execute_input":"2025-05-28T13:44:30.722461Z","iopub.status.idle":"2025-05-28T13:44:30.727249Z","shell.execute_reply.started":"2025-05-28T13:44:30.722443Z","shell.execute_reply":"2025-05-28T13:44:30.726287Z"}},"outputs":[],"execution_count":123},{"cell_type":"markdown","source":"w1=weight for first hidden layer,10 neurons,subtracting 0.5 so that the data is now centered at origin,this helps in avoiding a scenario when everything is 0(both w and b = 0),and all the neurons basically start learning the exact same things by picking up the exact same changes","metadata":{}},{"cell_type":"markdown","source":"w2=weight for the output layer connected to previous layer,the size is (current no of neurons,previous layer no of neurons)","metadata":{}},{"cell_type":"code","source":"def ReLu(Z):\n    return np.maximum(0,Z)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:35.567256Z","iopub.execute_input":"2025-05-28T13:44:35.567543Z","iopub.status.idle":"2025-05-28T13:44:35.571919Z","shell.execute_reply.started":"2025-05-28T13:44:35.567497Z","shell.execute_reply":"2025-05-28T13:44:35.570869Z"}},"outputs":[],"execution_count":124},{"cell_type":"markdown","source":"i dont understand ReLu's purrpose fully,what does it mean to remove non linearity ","metadata":{}},{"cell_type":"code","source":"def softmax(Z):\n    exp = np.exp(Z - np.max(Z))\n    return exp / exp.sum(axis=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:37.663976Z","iopub.execute_input":"2025-05-28T13:44:37.664871Z","iopub.status.idle":"2025-05-28T13:44:37.668521Z","shell.execute_reply.started":"2025-05-28T13:44:37.664843Z","shell.execute_reply":"2025-05-28T13:44:37.667746Z"}},"outputs":[],"execution_count":125},{"cell_type":"markdown","source":"now defining forward propagation algo","metadata":{}},{"cell_type":"code","source":"def forward_prop(W1,b1,W2,b2,X):\n    Z1=W1.dot(X) + b1\n    A1=ReLu(Z1)\n    Z2=W2.dot(A1) + b2\n    A2=softmax(Z2)\n    return Z1,A1,Z2,A2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:40.258830Z","iopub.execute_input":"2025-05-28T13:44:40.259095Z","iopub.status.idle":"2025-05-28T13:44:40.263558Z","shell.execute_reply.started":"2025-05-28T13:44:40.259075Z","shell.execute_reply":"2025-05-28T13:44:40.262732Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"def derivative_ReLu(Z):\n    # if (Z > 0):\n    #     return 1\n    # else:\n    #     return 0\n    return Z > 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:42.303183Z","iopub.execute_input":"2025-05-28T13:44:42.303929Z","iopub.status.idle":"2025-05-28T13:44:42.307544Z","shell.execute_reply.started":"2025-05-28T13:44:42.303906Z","shell.execute_reply":"2025-05-28T13:44:42.306740Z"}},"outputs":[],"execution_count":127},{"cell_type":"markdown","source":"we need to one hot encode our labels,we do this because it can create an error while computing the loss fucntion,we do this by basically making the correct label value as 1 and remaining else as 0,then we make a matrix of this,eg for label 2 , we make [0,0,1,0,0....,]  ","metadata":{}},{"cell_type":"code","source":"def one_hot_encode(Y):\n    arr=np.zeros((Y.size,Y.max()+1))\n    arr[np.arange(Y.size),Y]=1\n    arr=arr.T\n    return arr\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:43.764251Z","iopub.execute_input":"2025-05-28T13:44:43.764556Z","iopub.status.idle":"2025-05-28T13:44:43.769272Z","shell.execute_reply.started":"2025-05-28T13:44:43.764505Z","shell.execute_reply":"2025-05-28T13:44:43.768363Z"}},"outputs":[],"execution_count":128},{"cell_type":"code","source":"def back_propagation(Z1, A1, Z2, A2, W1, W2, X, Y):\n    m = Y.size\n    one_hot_Y = one_hot_encode(Y)\n    \n    dZ2 = A2 - one_hot_Y\n    dW2 = 1/m * dZ2.dot(A1.T)\n    db2 = 1/m * np.sum(dZ2)\n    dZ1 = W2.T.dot(dZ2) * derivative_ReLu(Z1)  \n    dW1 = 1/m * dZ1.dot(X.T)\n    db1 = 1/m * np.sum(dZ1)\n    \n    return dW1, db1, dW2, db2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:46.239162Z","iopub.execute_input":"2025-05-28T13:44:46.239427Z","iopub.status.idle":"2025-05-28T13:44:46.245168Z","shell.execute_reply.started":"2025-05-28T13:44:46.239408Z","shell.execute_reply":"2025-05-28T13:44:46.244342Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"def update_para(W1,b1,W2,b2,dW1,db1,dW2,db2,alpha):\n    W1=W1-alpha*dW1\n    b1=b1-alpha*db1\n    W2=W2-alpha*dW2\n    b2=b2-alpha*db2\n    return W1,b1,W2,b2\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:47.540214Z","iopub.execute_input":"2025-05-28T13:44:47.540806Z","iopub.status.idle":"2025-05-28T13:44:47.544925Z","shell.execute_reply.started":"2025-05-28T13:44:47.540778Z","shell.execute_reply":"2025-05-28T13:44:47.544093Z"}},"outputs":[],"execution_count":130},{"cell_type":"code","source":"def get_predictions(A2):\n    return np.argmax(A2, axis=0)\n\n\ndef get_accuracy(predictions, Y):\n    print(predictions, Y)\n    return np.sum(predictions == Y) / Y.size\n\n\n\ndef gradient_descent(X, Y, alpha, iterations):\n    W1, b1, W2, b2 = initialize_parameters()\n    for i in range(iterations):\n        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n        dW1, db1, dW2, db2 = back_propagation(Z1, A1, Z2, A2, W1, W2, X, Y)\n        W1, b1, W2, b2 = update_para(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n        if i % 10 == 0:\n            print(\"Iteration: \", i)\n            predictions = get_predictions(A2)\n            print(get_accuracy(predictions, Y))\n    return W1, b1, W2, b2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:48.835478Z","iopub.execute_input":"2025-05-28T13:44:48.835821Z","iopub.status.idle":"2025-05-28T13:44:48.842710Z","shell.execute_reply.started":"2025-05-28T13:44:48.835797Z","shell.execute_reply":"2025-05-28T13:44:48.841672Z"}},"outputs":[],"execution_count":131},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:44:54.816302Z","iopub.execute_input":"2025-05-28T13:44:54.816577Z","iopub.status.idle":"2025-05-28T13:45:29.722916Z","shell.execute_reply.started":"2025-05-28T13:44:54.816558Z","shell.execute_reply":"2025-05-28T13:45:29.722052Z"}},"outputs":[{"name":"stdout","text":"Iteration:  0\n[5 5 5 ... 5 2 5] [4 3 6 ... 1 4 5]\n0.0873170731707317\nIteration:  10\n[6 0 5 ... 5 7 6] [4 3 6 ... 1 4 5]\n0.21529268292682927\nIteration:  20\n[6 5 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.2936829268292683\nIteration:  30\n[6 5 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.3580243902439024\nIteration:  40\n[8 5 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.4161463414634146\nIteration:  50\n[8 5 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.46375609756097563\nIteration:  60\n[4 5 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.4997560975609756\nIteration:  70\n[4 3 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.528\nIteration:  80\n[4 3 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.5531219512195122\nIteration:  90\n[4 3 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.5754634146341463\nIteration:  100\n[4 3 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.5974878048780488\nIteration:  110\n[4 3 5 ... 1 7 5] [4 3 6 ... 1 4 5]\n0.616609756097561\nIteration:  120\n[4 3 5 ... 1 9 5] [4 3 6 ... 1 4 5]\n0.6351707317073171\nIteration:  130\n[4 3 5 ... 1 9 5] [4 3 6 ... 1 4 5]\n0.6543658536585366\nIteration:  140\n[4 3 5 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.6697073170731708\nIteration:  150\n[4 3 5 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.6845365853658537\nIteration:  160\n[4 3 5 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.6973170731707317\nIteration:  170\n[4 3 5 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7101219512195122\nIteration:  180\n[4 3 5 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7211463414634146\nIteration:  190\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7319512195121951\nIteration:  200\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7418536585365854\nIteration:  210\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7503658536585366\nIteration:  220\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7576585365853659\nIteration:  230\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7644390243902439\nIteration:  240\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.770829268292683\nIteration:  250\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7765609756097561\nIteration:  260\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7821463414634147\nIteration:  270\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7873902439024391\nIteration:  280\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7921463414634147\nIteration:  290\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.7959512195121952\nIteration:  300\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8000731707317074\nIteration:  310\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8037804878048781\nIteration:  320\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8071951219512196\nIteration:  330\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8107317073170732\nIteration:  340\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.813560975609756\nIteration:  350\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8164878048780487\nIteration:  360\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8189756097560975\nIteration:  370\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8215121951219512\nIteration:  380\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8241951219512195\nIteration:  390\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8263658536585365\nIteration:  400\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.828780487804878\nIteration:  410\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8308780487804878\nIteration:  420\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8330243902439024\nIteration:  430\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8346097560975609\nIteration:  440\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8363414634146341\nIteration:  450\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8377317073170731\nIteration:  460\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8389268292682927\nIteration:  470\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8402926829268292\nIteration:  480\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8420975609756097\nIteration:  490\n[4 3 6 ... 1 4 5] [4 3 6 ... 1 4 5]\n0.8434634146341463\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"print(\"Now training for more iterations(1000) \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:52:56.830225Z","iopub.execute_input":"2025-05-28T12:52:56.830490Z","iopub.status.idle":"2025-05-28T12:52:56.834838Z","shell.execute_reply.started":"2025-05-28T12:52:56.830470Z","shell.execute_reply":"2025-05-28T12:52:56.833885Z"}},"outputs":[{"name":"stdout","text":"Now training for more iterations(1000) \n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T12:40:03.937141Z","iopub.execute_input":"2025-05-28T12:40:03.937714Z","iopub.status.idle":"2025-05-28T12:41:12.905796Z","shell.execute_reply.started":"2025-05-28T12:40:03.937668Z","shell.execute_reply":"2025-05-28T12:41:12.904888Z"}},"outputs":[{"name":"stdout","text":"Iteration:  0\n[6 6 6 ... 6 6 6] [0 5 5 ... 2 7 1]\n0.11721951219512194\nIteration:  10\n[5 5 7 ... 6 7 1] [0 5 5 ... 2 7 1]\n0.22273170731707317\nIteration:  20\n[0 5 7 ... 6 7 1] [0 5 5 ... 2 7 1]\n0.320609756097561\nIteration:  30\n[0 5 6 ... 7 7 1] [0 5 5 ... 2 7 1]\n0.3838536585365854\nIteration:  40\n[0 5 7 ... 7 7 8] [0 5 5 ... 2 7 1]\n0.4484390243902439\nIteration:  50\n[0 5 7 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.5095609756097561\nIteration:  60\n[0 5 7 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.5594878048780488\nIteration:  70\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.5968780487804878\nIteration:  80\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.6244146341463415\nIteration:  90\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.645390243902439\nIteration:  100\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.6630487804878049\nIteration:  110\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.6778536585365854\nIteration:  120\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.6917073170731707\nIteration:  130\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7028292682926829\nIteration:  140\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7126585365853658\nIteration:  150\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7226341463414634\nIteration:  160\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7304634146341463\nIteration:  170\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7380243902439024\nIteration:  180\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7455853658536585\nIteration:  190\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.753\nIteration:  200\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7595121951219512\nIteration:  210\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7654146341463415\nIteration:  220\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7710243902439025\nIteration:  230\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7756585365853659\nIteration:  240\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7804878048780488\nIteration:  250\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7845853658536586\nIteration:  260\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7888048780487805\nIteration:  270\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7934878048780488\nIteration:  280\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.7981463414634147\nIteration:  290\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8017317073170732\nIteration:  300\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8055365853658537\nIteration:  310\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8098048780487805\nIteration:  320\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8139756097560975\nIteration:  330\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8165365853658536\nIteration:  340\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8191951219512195\nIteration:  350\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8220243902439024\nIteration:  360\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8247317073170731\nIteration:  370\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8276097560975609\nIteration:  380\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8297073170731707\nIteration:  390\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8318780487804878\nIteration:  400\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8342926829268292\nIteration:  410\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.836390243902439\nIteration:  420\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8385121951219512\nIteration:  430\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8405609756097561\nIteration:  440\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8421463414634146\nIteration:  450\n[0 5 2 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8439024390243902\nIteration:  460\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8458292682926829\nIteration:  470\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8478780487804878\nIteration:  480\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8490243902439024\nIteration:  490\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8505121951219512\nIteration:  500\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8519512195121951\nIteration:  510\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8532926829268292\nIteration:  520\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8548048780487805\nIteration:  530\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8559756097560975\nIteration:  540\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8573170731707317\nIteration:  550\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8588780487804878\nIteration:  560\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8600975609756097\nIteration:  570\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8611219512195122\nIteration:  580\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8620243902439024\nIteration:  590\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8630975609756097\nIteration:  600\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8641951219512195\nIteration:  610\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8650731707317073\nIteration:  620\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8661951219512195\nIteration:  630\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8670731707317073\nIteration:  640\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.868\nIteration:  650\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.868609756097561\nIteration:  660\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8694146341463415\nIteration:  670\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8701463414634146\nIteration:  680\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8709024390243902\nIteration:  690\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.871609756097561\nIteration:  700\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8722682926829268\nIteration:  710\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8729024390243902\nIteration:  720\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8737073170731707\nIteration:  730\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8745609756097561\nIteration:  740\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8751463414634146\nIteration:  750\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8760487804878049\nIteration:  760\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8767317073170732\nIteration:  770\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8772682926829268\nIteration:  780\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8778536585365854\nIteration:  790\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8784634146341463\nIteration:  800\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8791463414634146\nIteration:  810\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8796829268292683\nIteration:  820\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.880219512195122\nIteration:  830\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8806585365853659\nIteration:  840\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8811219512195122\nIteration:  850\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8815609756097561\nIteration:  860\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8820243902439024\nIteration:  870\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8826829268292683\nIteration:  880\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8835365853658537\nIteration:  890\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.884\nIteration:  900\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8841707317073171\nIteration:  910\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8844634146341463\nIteration:  920\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8852439024390244\nIteration:  930\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8857560975609756\nIteration:  940\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8863170731707317\nIteration:  950\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8867560975609756\nIteration:  960\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.887219512195122\nIteration:  970\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8876585365853659\nIteration:  980\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8881707317073171\nIteration:  990\n[0 5 5 ... 2 7 1] [0 5 5 ... 2 7 1]\n0.8884878048780488\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"The model is now 88 percent accurate","metadata":{}},{"cell_type":"markdown","source":"Now trying it on the test dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nn-from-scratch-1/test 2.csv')\ndf = np.array(df)\nnp.random.shuffle(df)\ndf_test = df.T\nY_test = df_test[0]\nX_test = df_test[1:785] \nX_test = X_test / 255.\nW1 = W1[:, :783]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:15:42.480329Z","iopub.execute_input":"2025-05-28T13:15:42.480626Z","iopub.status.idle":"2025-05-28T13:15:44.310142Z","shell.execute_reply.started":"2025-05-28T13:15:42.480606Z","shell.execute_reply":"2025-05-28T13:15:44.309441Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"print(X_test.shape)  # should be (784, number of test samples)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:15:44.311321Z","iopub.execute_input":"2025-05-28T13:15:44.311590Z","iopub.status.idle":"2025-05-28T13:15:44.316040Z","shell.execute_reply.started":"2025-05-28T13:15:44.311563Z","shell.execute_reply":"2025-05-28T13:15:44.315178Z"}},"outputs":[{"name":"stdout","text":"(783, 28000)\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_test)\npredictions = np.argmax(A2, axis=0)\naccuracy = np.mean(predictions == Y_test) * 100\nprint(f\"Test Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:16:01.468322Z","iopub.execute_input":"2025-05-28T13:16:01.468566Z","iopub.status.idle":"2025-05-28T13:16:01.517520Z","shell.execute_reply.started":"2025-05-28T13:16:01.468549Z","shell.execute_reply":"2025-05-28T13:16:01.516824Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 9.58%\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"Testing on validation dataset","metadata":{}},{"cell_type":"code","source":"\ndf_val_dataset = df[0:1000].T\nY_val = df_val_dataset[0]\nX_val = df_val_dataset[1:n]\nX_val=X_val/255.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:45:53.111548Z","iopub.execute_input":"2025-05-28T13:45:53.112167Z","iopub.status.idle":"2025-05-28T13:45:53.119893Z","shell.execute_reply.started":"2025-05-28T13:45:53.112140Z","shell.execute_reply":"2025-05-28T13:45:53.118923Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_val)\ndef get_predictions(A2):\n    return np.argmax(A2, axis=0)\n\n\ndef get_accuracy(predictions, Y):\n    print(predictions, Y)\n    return np.sum(predictions == Y) / Y.size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:46:00.856062Z","iopub.execute_input":"2025-05-28T13:46:00.856338Z","iopub.status.idle":"2025-05-28T13:46:00.862452Z","shell.execute_reply.started":"2025-05-28T13:46:00.856317Z","shell.execute_reply":"2025-05-28T13:46:00.861546Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_val)\npredictions = get_predictions(A2)\naccuracy = get_accuracy(predictions, Y_val)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T13:46:12.783339Z","iopub.execute_input":"2025-05-28T13:46:12.783626Z","iopub.status.idle":"2025-05-28T13:46:12.793321Z","shell.execute_reply.started":"2025-05-28T13:46:12.783604Z","shell.execute_reply":"2025-05-28T13:46:12.792350Z"}},"outputs":[{"name":"stdout","text":"[6 4 4 5 5 4 1 3 5 1 3 0 1 7 9 8 9 5 4 1 3 8 0 2 8 4 6 5 5 6 5 0 4 0 9 1 6\n 6 7 4 2 0 0 3 9 6 3 3 7 6 9 1 7 7 1 3 8 5 4 5 1 8 3 2 0 2 9 9 9 4 7 3 2 9\n 8 4 6 8 2 7 0 4 3 0 9 5 0 6 5 7 2 7 3 6 7 7 9 1 0 8 6 1 1 3 0 5 4 1 1 3 5\n 0 0 4 0 4 3 9 1 5 1 2 1 8 2 4 5 4 5 5 6 4 9 9 2 1 7 2 8 1 1 6 4 4 9 4 2 5\n 8 0 6 5 2 6 5 0 6 3 3 6 0 4 6 1 9 0 1 7 0 6 5 2 7 7 3 9 8 5 5 0 5 6 2 9 1\n 7 4 1 6 4 2 1 7 1 9 6 9 8 8 8 6 9 6 3 9 0 0 2 3 5 7 8 7 7 8 7 8 4 7 2 8 9\n 9 0 1 4 3 2 0 1 5 4 2 1 0 0 4 5 0 1 1 9 6 1 4 9 9 2 7 4 7 5 0 6 7 9 2 1 6\n 5 1 7 1 3 2 4 9 3 3 9 3 4 6 2 5 1 6 4 6 1 9 4 4 8 0 2 7 3 0 2 4 0 8 9 3 1\n 4 2 1 6 0 8 7 9 6 2 5 3 9 6 7 7 2 8 7 1 2 7 5 5 0 4 4 3 4 7 6 7 4 8 9 4 4\n 2 7 9 2 3 3 2 7 0 5 3 6 1 1 1 2 5 1 0 7 1 6 9 0 9 5 1 3 4 9 0 0 3 9 3 5 8\n 6 8 1 6 7 0 3 4 8 7 5 2 8 0 0 4 1 2 1 6 9 9 9 6 2 0 5 1 1 4 3 7 6 7 3 6 5\n 9 4 6 1 2 4 8 7 1 1 5 3 9 4 2 1 9 3 9 4 5 5 6 1 8 2 0 9 4 4 4 4 6 7 0 3 4\n 7 7 6 6 7 5 9 8 9 8 7 7 1 7 8 1 3 2 8 2 0 7 6 1 7 5 3 0 6 6 2 8 4 2 3 5 9\n 8 5 4 7 4 7 8 5 3 6 5 2 8 9 5 4 4 7 0 7 5 1 6 7 0 5 7 3 5 5 5 7 5 6 4 9 1\n 7 0 7 2 7 6 5 9 2 8 9 1 1 1 5 3 6 6 9 2 8 1 6 6 9 4 6 4 8 4 1 2 9 4 6 3 8\n 6 1 3 1 1 1 2 3 9 8 9 9 0 7 2 5 4 4 1 9 4 6 6 3 0 7 4 4 4 0 2 2 6 0 9 6 3\n 8 3 7 1 2 0 5 0 1 2 3 6 5 0 2 3 1 5 7 1 6 8 7 4 4 3 3 4 5 7 9 8 8 3 0 3 6\n 9 0 4 9 5 0 1 1 5 4 4 3 0 2 1 2 2 0 9 3 4 1 9 3 2 9 1 0 1 5 2 0 7 7 1 8 5\n 5 0 5 1 5 9 1 7 7 0 1 0 9 6 1 5 7 2 9 3 7 6 3 5 7 4 1 4 2 1 8 1 1 7 0 5 0\n 4 2 2 2 7 6 9 7 8 2 4 9 9 0 9 6 7 1 9 9 7 6 5 0 8 3 4 5 3 7 0 9 5 2 4 8 5\n 8 7 3 4 9 3 6 8 3 9 7 4 2 0 3 5 8 8 7 3 2 8 4 7 0 2 2 2 2 8 7 4 4 0 9 5 7\n 0 9 8 9 9 1 1 0 8 1 5 5 6 1 1 8 6 7 9 5 7 7 4 6 5 7 5 5 9 1 1 9 9 0 7 3 6\n 7 4 4 2 8 0 5 5 4 7 1 1 4 3 4 9 4 8 9 9 2 0 5 5 8 8 7 1 1 1 3 7 9 7 8 0 6\n 0 1 2 8 8 4 9 8 1 4 0 6 6 9 2 7 4 4 4 3 3 1 6 0 4 6 6 5 6 9 4 4 2 2 5 4 8\n 7 6 9 9 4 2 0 0 0 7 7 8 6 5 8 0 9 0 5 6 1 8 8 3 0 4 6 9 2 7 8 3 8 7 5 7 4\n 0 2 6 0 3 9 5 5 9 1 5 1 6 7 1 1 5 8 6 0 2 9 1 3 8 3 6 1 1 5 6 1 5 0 0 9 4\n 8 8 0 1 9 0 0 4 8 3 1 3 3 7 0 5 6 6 1 5 0 4 2 8 7 7 1 3 9 6 3 8 5 6 7 5 9\n 4] [6 4 4 5 5 4 1 1 3 1 3 0 1 7 7 8 4 5 4 1 3 8 0 2 8 4 6 5 5 6 5 0 4 0 9 1 2\n 6 9 4 2 0 0 3 9 6 3 3 9 6 9 1 7 7 1 3 8 5 4 3 1 8 3 7 0 2 9 9 4 4 7 3 2 4\n 2 4 6 8 2 7 0 4 7 0 9 5 0 6 5 7 2 7 5 6 7 7 9 1 0 4 6 1 1 3 0 5 8 1 1 3 5\n 0 0 4 0 4 3 9 1 5 1 2 1 8 7 4 5 4 5 5 6 4 9 9 2 1 7 2 8 1 1 6 4 4 9 4 2 5\n 8 0 6 3 2 6 5 0 6 3 3 6 0 4 6 1 4 0 1 7 0 8 5 2 7 7 3 9 2 5 5 0 5 6 2 9 1\n 7 4 1 6 4 5 1 7 1 7 6 4 8 5 8 2 9 6 3 4 0 0 2 3 8 7 8 7 7 8 7 8 4 7 2 8 9\n 9 0 1 4 5 2 0 1 3 4 2 1 0 5 4 3 0 1 1 9 6 1 4 9 9 3 3 9 7 5 0 6 7 9 2 1 6\n 5 1 2 1 3 2 4 4 0 3 4 1 4 5 2 5 1 6 4 6 1 9 4 4 8 0 2 7 3 0 2 4 0 8 7 3 1\n 4 2 1 6 0 8 7 9 6 2 5 3 4 6 7 7 2 9 7 1 2 7 5 5 0 4 4 3 9 7 6 3 4 8 4 4 4\n 2 7 9 2 3 3 2 7 0 5 3 8 5 1 1 2 5 1 0 7 1 6 9 0 9 5 1 3 4 9 0 0 8 7 3 5 8\n 6 8 1 6 7 0 3 4 8 7 3 2 8 0 0 4 1 2 1 6 9 9 9 6 2 0 5 1 1 4 3 7 6 9 3 6 5\n 7 4 5 1 7 7 8 7 1 1 8 3 9 4 2 1 9 3 9 4 9 5 6 1 8 2 0 7 4 4 4 4 6 7 0 3 4\n 7 7 6 6 9 5 9 8 9 8 7 7 1 7 8 1 3 2 2 2 0 7 6 1 7 5 3 0 6 6 2 2 4 2 3 6 9\n 3 5 4 7 4 7 8 4 3 6 5 2 8 9 5 4 4 7 0 7 5 1 6 7 0 8 7 3 3 5 5 7 5 6 4 9 1\n 7 0 7 6 7 6 5 9 2 8 4 1 1 1 5 3 6 6 9 2 8 1 6 6 9 4 6 0 8 4 5 1 4 4 6 3 8\n 5 1 3 1 2 1 2 3 9 8 7 9 0 7 2 5 4 4 1 9 9 5 0 1 0 7 4 4 4 0 2 2 6 0 9 6 3\n 8 3 7 8 2 0 5 0 1 2 3 6 3 0 2 3 9 5 7 1 6 8 7 4 4 5 3 4 5 7 9 0 8 3 0 3 6\n 9 0 4 9 5 0 1 1 5 9 4 3 0 2 1 2 2 0 9 3 4 1 9 0 2 9 1 0 1 5 2 0 7 7 7 8 5\n 5 0 5 1 5 9 1 9 7 0 1 0 9 6 1 5 7 2 9 5 7 6 3 8 7 4 1 4 2 1 9 1 1 7 0 5 0\n 4 2 2 6 9 6 9 7 9 2 4 9 9 0 9 6 9 1 9 3 7 6 5 0 5 3 4 5 3 2 0 9 5 2 4 8 5\n 8 2 3 4 4 8 6 8 9 9 7 4 2 0 5 3 2 8 7 3 2 8 4 7 8 2 2 2 2 8 7 4 8 0 9 3 7\n 0 9 9 9 9 1 1 0 8 1 3 6 6 1 1 8 6 7 9 5 7 7 9 6 5 9 5 5 9 1 1 9 9 0 7 8 6\n 7 9 4 2 8 0 5 8 4 7 1 1 4 5 4 9 4 8 9 4 6 0 5 5 9 4 7 1 1 1 3 7 7 7 8 0 4\n 0 1 2 8 8 4 9 8 1 4 0 6 6 9 2 7 4 4 4 3 3 1 6 0 8 6 6 5 5 7 4 4 2 2 5 4 8\n 9 6 9 9 4 8 0 0 0 7 7 8 6 5 8 0 9 0 5 6 1 8 3 3 0 4 6 4 2 7 8 3 8 7 9 7 2\n 0 2 6 2 3 9 5 5 4 1 5 1 6 0 1 1 8 2 6 0 3 9 1 3 5 8 6 1 1 5 6 1 8 0 0 8 4\n 8 8 0 1 9 2 0 4 8 3 1 1 8 7 0 5 6 6 1 5 0 4 2 8 7 7 1 3 9 5 3 8 5 6 7 5 9\n 4]\nValidation Accuracy: 85.20%\n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}